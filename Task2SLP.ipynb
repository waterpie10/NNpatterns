{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Single Layer Perceptron\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Original training images shape: (60000, 28, 28)\n",
      "Original training labels shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Check the shape of the data\n",
    "print(\"Original training images shape:\", train_images.shape)\n",
    "print(\"Original training labels shape:\", train_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training images shape: (60000, 28, 28)\n",
      "Reshaped training images shape: (60000, 784)\n",
      "Reshaped test images shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# --- Preprocess the Data ---\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "# Convert to float32 first to ensure the division results in a float, not an integer.\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the images from (28, 28) to a flat vector of 784 elements\n",
    "train_images_flat = train_images.reshape(train_images.shape[0], 784)\n",
    "test_images_flat = test_images.reshape(test_images.shape[0], 784)\n",
    "\n",
    "# Check the new shape to confirm it's correct\n",
    "print(f\"Original training images shape: {train_images.shape}\")\n",
    "print(f\"Reshaped training images shape: {train_images_flat.shape}\")\n",
    "print(f\"Reshaped test images shape: {test_images_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training labels shape: (60000,)\n",
      "One-hot encoded training labels shape: (60000, 10)\n",
      "\n",
      "--- Example ---\n",
      "Original first label: 5\n",
      "One-hot encoded first label: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# --- One-Hot Encode the Labels ---\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels_one_hot = to_categorical(train_labels, num_classes=10)\n",
    "test_labels_one_hot = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "# Check the new shape of the labels and look at an example\n",
    "print(\"Original training labels shape:\", train_labels.shape)\n",
    "print(\"One-hot encoded training labels shape:\", train_labels_one_hot.shape)\n",
    "\n",
    "print(\"\\n--- Example ---\")\n",
    "print(\"Original first label:\", train_labels[0])\n",
    "print(\"One-hot encoded first label:\", train_labels_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights matrix shape: (784, 10)\n",
      "Biases vector shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize SLP Parameters ---\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "# Weights: A matrix of 784 x 10 small random numbers\n",
    "# Biases: A vector of 10 small random numbers\n",
    "weights = np.random.rand(784, 10) * 0.1\n",
    "biases = np.random.rand(10) * 0.1\n",
    "\n",
    "print(\"Weights matrix shape:\", weights.shape)\n",
    "print(\"Biases vector shape:\", biases.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on small subset (6000 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a smaller training set for initial runs.\n",
      "Images shape: (6000, 784)\n",
      "Labels shape: (6000, 10)\n"
     ]
    }
   ],
   "source": [
    "# --- Prepare for Training ---\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Using a smaller subset of the training data for initial runs\n",
    "num_train_samples = 6000\n",
    "train_images_small = train_images_flat[:num_train_samples]\n",
    "train_labels_small = train_labels_one_hot[:num_train_samples]\n",
    "\n",
    "print(\"Using a smaller training set for initial runs.\")\n",
    "print(\"Images shape:\", train_images_small.shape)\n",
    "print(\"Labels shape:\", train_labels_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1/10 ---\n",
      "Training Accuracy: 89.45%\n",
      "--- Epoch 2/10 ---\n",
      "Training Accuracy: 90.97%\n",
      "--- Epoch 3/10 ---\n",
      "Training Accuracy: 91.70%\n",
      "--- Epoch 4/10 ---\n",
      "Training Accuracy: 92.18%\n",
      "--- Epoch 5/10 ---\n",
      "Training Accuracy: 92.55%\n",
      "--- Epoch 6/10 ---\n",
      "Training Accuracy: 92.73%\n",
      "--- Epoch 7/10 ---\n",
      "Training Accuracy: 92.85%\n",
      "--- Epoch 8/10 ---\n",
      "Training Accuracy: 93.00%\n",
      "--- Epoch 9/10 ---\n",
      "Training Accuracy: 93.27%\n",
      "--- Epoch 10/10 ---\n",
      "Training Accuracy: 93.43%\n"
     ]
    }
   ],
   "source": [
    "# --- SLP Training Loop ---\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"--- Epoch {epoch + 1}/{epochs} ---\")\n",
    "    \n",
    "    # Loop through each image (x) and its one-hot label (d) in small training set\n",
    "    for x, d in zip(train_images_small, train_labels_small):\n",
    "        \n",
    "        # 1. FORWARD PASS\n",
    "        # Calculate the output 'y' for all 10 neurons\n",
    "        \n",
    "         # Calculate the raw output v \n",
    "        raw_output_v = np.dot(x, weights) + biases\n",
    "         # Apply the sigmoid activation function to get the final output y\n",
    "        final_output_y = sigmoid(raw_output_v)\n",
    "\n",
    "        # 2. BACKWARD PASS (Weight and Bias Update)\n",
    "        # Using the Delta Rule:\n",
    "        # w(t+1) = w(t) + α[d(t)-y(t)]y(t)[1-y(t)]x(t)\n",
    "        # b(t+1) = b(t) + α[d(t)-y(t)]y(t)[1-y(t)]\n",
    "\n",
    "        # Calculate the delta term\n",
    "        delta = (d - final_output_y) * final_output_y * (1 - final_output_y)\n",
    "\n",
    "        # Update weights matrix\n",
    "        weights += learning_rate * np.outer(x, delta)\n",
    "        # Update biases vector\n",
    "        biases += learning_rate * delta\n",
    "\n",
    "    # 3. TRACK PERFORMANCE (at the end of each epoch)\n",
    "\n",
    "    # Calculate predictions on the small training set\n",
    "    predictions = sigmoid(np.dot(train_images_small, weights) + biases)\n",
    "\n",
    "    # Get the class with the highest output value for each image\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Get the true classes (non-one-hot)\n",
    "    true_classes = np.argmax(train_labels_small, axis=1)\n",
    "    \n",
    "    accuracy = np.mean(predicted_classes == true_classes)\n",
    "    print(f\"Training Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 89.97%\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate the SLP on the Test Set ---\n",
    "\n",
    "# Perform a forward pass on the full test data using the final trained weights and biases\n",
    "test_predictions = sigmoid(np.dot(test_images_flat, weights) + biases)\n",
    "\n",
    "# Get the predicted class for each test image by finding the index of the max output value\n",
    "test_predicted_classes = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Get the true class for each test image from the one-hot encoded labels\n",
    "test_true_classes = np.argmax(test_labels_one_hot, axis=1)\n",
    "\n",
    "# Calculate the accuracy by comparing the predicted classes to the true classes\n",
    "test_accuracy = np.mean(test_predicted_classes == test_true_classes)\n",
    "\n",
    "print(f\"Final Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on full subset (60000 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1/10 ---\n",
      "Training Accuracy: 90.13%\n",
      "--- Epoch 2/10 ---\n",
      "Training Accuracy: 90.55%\n",
      "--- Epoch 3/10 ---\n",
      "Training Accuracy: 90.87%\n",
      "--- Epoch 4/10 ---\n",
      "Training Accuracy: 91.09%\n",
      "--- Epoch 5/10 ---\n",
      "Training Accuracy: 91.24%\n",
      "--- Epoch 6/10 ---\n",
      "Training Accuracy: 91.32%\n",
      "--- Epoch 7/10 ---\n",
      "Training Accuracy: 91.42%\n",
      "--- Epoch 8/10 ---\n",
      "Training Accuracy: 91.49%\n",
      "--- Epoch 9/10 ---\n",
      "Training Accuracy: 91.53%\n",
      "--- Epoch 10/10 ---\n",
      "Training Accuracy: 91.57%\n"
     ]
    }
   ],
   "source": [
    "# --- SLP Training Loop ---\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"--- Epoch {epoch + 1}/{epochs} ---\")\n",
    "    \n",
    "    # Loop through each image (x) and its one-hot label (d) in small training set\n",
    "    for x, d in zip(train_images_flat, train_labels_one_hot):\n",
    "        \n",
    "        # 1. FORWARD PASS\n",
    "        # Calculate the output 'y' for all 10 neurons\n",
    "        \n",
    "         # Calculate the raw output v \n",
    "        raw_output_v = np.dot(x, weights) + biases\n",
    "         # Apply the sigmoid activation function to get the final output y\n",
    "        final_output_y = sigmoid(raw_output_v)\n",
    "\n",
    "        # 2. BACKWARD PASS (Weight and Bias Update)\n",
    "        # Using the Delta Rule:\n",
    "        # w(t+1) = w(t) + α[d(t)-y(t)]y(t)[1-y(t)]x(t)\n",
    "        # b(t+1) = b(t) + α[d(t)-y(t)]y(t)[1-y(t)]\n",
    "\n",
    "        # Calculate the delta term\n",
    "        delta = (d - final_output_y) * final_output_y * (1 - final_output_y)\n",
    "\n",
    "        # Update weights matrix\n",
    "        weights += learning_rate * np.outer(x, delta)\n",
    "        # Update biases vector\n",
    "        biases += learning_rate * delta\n",
    "\n",
    "    # 3. TRACK PERFORMANCE (at the end of each epoch)\n",
    "\n",
    "    # Calculate predictions on the small training set\n",
    "    predictions = sigmoid(np.dot(train_images_flat, weights) + biases)\n",
    "\n",
    "    # Get the class with the highest output value for each image\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Get the true classes (non-one-hot)\n",
    "    true_classes = np.argmax(train_labels_one_hot, axis=1)\n",
    "    \n",
    "    accuracy = np.mean(predicted_classes == true_classes)\n",
    "    print(f\"Training Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pattern_recognition_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
